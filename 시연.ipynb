{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7b05c77-f1ef-455a-8f18-5580933b21d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kc9302/AI_Agent/ì‹œì—°/multi_agent.py:15: UserWarning: WARNING: Unsloth should be imported before transformers to ensure all optimizations are applied. Your code may run slower or encounter memory issues without these optimizations.\n",
      "\n",
      "Please restructure your imports with 'import unsloth' at the top of your file.\n",
      "  from unsloth import FastLanguageModel\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "Unsloth: Failed to patch Gemma3ForConditionalGeneration.\n",
      "ğŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 04-10 04:37:40 [__init__.py:239] Automatically detected platform cuda.\n"
     ]
    }
   ],
   "source": [
    "from make_langgraph import activate_agent\n",
    "import time\n",
    "\n",
    "# ì§ˆì˜ ë³€ìˆ˜ ìƒì„±\n",
    "korea_history = \"ì´ìˆœì‹  ì¥êµ°ì˜ ì ˆì¹œì€?\"\n",
    "english = \"ì˜ì–´ë¡œ ì½”ë¼ë¦¬ëŠ” ë­ë¼ê³ í•´ìš”?\"\n",
    "math = \"\"\"\"ìœ„í‚¤ìŒ¤ ì´ ë¬¸ì œë¥¼ ì´ˆë“±í•™ìƒ ìˆ˜í•™ ê³„í†µë„ ì•ˆì—ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”.\n",
    "ê°€ë¡œì˜ ê¸¸ì´ê°€ ì„¸ë¡œì˜ ê¸¸ì´ë³´ë‹¤ 9 cmë§Œí¼ ë” ê¸´ ì§ì‚¬ê°í˜•ì˜ë‘˜ë ˆì˜ ê¸¸ì´ê°€ 50 cmì¼ ë•Œ, ì§ì‚¬ê°í˜•ì˜ ë„“ì´ë¥¼ êµ¬í•˜ì‹œì˜¤.\n",
    "x í‘œí˜„ì€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”.\n",
    "ë˜ë„ë¡ ë¯¸ì§€ìˆ˜ëŠ” â–¡, â–³ë¡œ ë§í•´ì£¼ì„¸ìš”.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a06a0e8f-972b-41be-aa26-0931a8c92932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ ì§ˆì˜ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. ------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0908766f0e61446ab6cd151d96e83d4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ í•œêµ­ì‚¬ ë‹µë³€ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤. ------------\n",
      "\n",
      "------------ RAGì„ êµ¬ì„±í•©ë‹ˆë‹¤. ------------\n",
      "------------ RAGì—ì„œ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. ------------\n",
      "------------ ê°€ì ¸ì˜¨ ë°ì´í„° ------------\n",
      "page_content='í•œêµ­ì‚¬ ì‹ ì„ê¸° ì‹œëŒ€ ì™„ë²½ ì •ë¦¬\n",
      "í•œêµ­ì‚¬ ì‹ ì„ê¸° ì‹œëŒ€ëŠ” ê¸°ì›ì „ 8000ë…„ê²½ë¶€í„° ì‹œì‘ë˜ì–´ ê¸°ì›ì „ 1500ë…„ê²½ê¹Œì§€ ì´ì–´ì§„ ì‹œê¸°ì…ë‹ˆë‹¤. ì´ ì‹œê¸°ëŠ” ì¸ë¥˜ê°€ ê°„ì„ê¸°ë¥¼ ì‚¬ìš©í•˜ê³  ë†ê²½ê³¼ ëª©ì¶•ì„ ì‹œì‘í•˜ë©° ì •ì°© ìƒí™œì„ í•˜ê²Œ ëœ ì‹œê¸°ë¡œ, ë‹¤ìŒê³¼ ê°™ì´ ì •ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.' metadata={'source': 'rag_file.txt'}\n",
      "page_content='4. êµ¬ì„ê¸° ì‹œëŒ€ì˜ ì˜ì˜\n",
      "í•œë°˜ë„ ì¸ë¥˜ ì—­ì‚¬ì˜ ì‹œì‘: êµ¬ì„ê¸° ì‹œëŒ€ëŠ” í•œë°˜ë„ì—ì„œ ì¸ë¥˜ê°€ ì²˜ìŒìœ¼ë¡œ ì‚´ê¸° ì‹œì‘í•œ ì‹œê¸°ë¡œ, í•œêµ­ ì—­ì‚¬ì˜ ì‹œì‘ì„ ì•Œë¦¬ëŠ” ì¤‘ìš”í•œ ì‹œê¸°ì…ë‹ˆë‹¤.\n",
      "ì¸ë¥˜ ì§„í™” ê³¼ì • ì—°êµ¬ì˜ ì¤‘ìš”í•œ ìë£Œ: êµ¬ì„ê¸° ì‹œëŒ€ ìœ ì ê³¼ ìœ ë¬¼ì€ ì¸ë¥˜ì˜ ì§„í™” ê³¼ì •ê³¼ ë‹¹ì‹œ ìƒí™œ ëª¨ìŠµì„ ì—°êµ¬í•˜ëŠ” ë° ì¤‘ìš”í•œ ìë£Œë¥¼ ì œê³µí•©ë‹ˆë‹¤.' metadata={'source': 'rag_file.txt'}\n",
      "\n",
      "------------ í•œêµ­ì‚¬ ì—ì´ì „íŠ¸ ì‹¤í–‰ ------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae8e4904375f429f9d14fd044acdee3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------ Answer ------------\n",
      "ì‹ ì„ê¸° ì‹œëŒ€ì˜ íŠ¹ì§•ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤:1\n",
      " **ì¸ë¥˜ê°€ ì •ì°© ìƒí™œì„ ì‹œì‘í•¨**: ì‹ ì„ê¸° ì‹œëŒ€ì—ëŠ” ì¸ë¥˜ê°€ ê°„ì„ê¸°ë¥¼ ì‚¬ìš©í•˜ê³  ë†ê²½ê³¼ ëª©ì¶•ì„ ì‹œì‘í•˜ë©´ì„œ ì •ì°© ìƒí™œì„ ì‹œì‘í•˜ì˜€ìŠµë‹ˆë‹¤\n",
      "2\n",
      " **ì¸ë¥˜ ì—­ì‚¬ì˜ ì¤‘ìš”í•œ ì‹œì‘**: ì‹ ì„ê¸° ì‹œëŒ€ëŠ” í•œë°˜ë„ì—ì„œ ì¸ë¥˜ê°€ ì²˜ìŒìœ¼ë¡œ ì‚´ê¸° ì‹œì‘í•œ ì‹œê¸°ì´ë¯€ë¡œ í•œêµ­ ì—­ì‚¬ì˜ ì‹œì‘ì„ ì•Œë¦¬ëŠ” ì¤‘ìš”í•œ ì‹œê¸°ì…ë‹ˆë‹¤\n",
      "3\n",
      " **ì¸ë¥˜ ì§„í™” ê³¼ì • ì—°êµ¬ì˜ ìë£Œ**: ì‹ ì„ê¸° ì‹œëŒ€ì˜ ìœ ì ê³¼ ìœ ë¬¼ì€ ì¸ë¥˜ì˜ ì§„í™” ê³¼ì •ê³¼ ë‹¹ì‹œ ìƒí™œìƒì„ ì—°êµ¬í•˜ëŠ”ë° ì¤‘ìš”í•œ ìë£Œë¥¼ ì œê³µí•©ë‹ˆë‹¤\n",
      "ë”°ë¼ì„œ, ì‹ ì„ê¸° ì‹œëŒ€ëŠ” ì¸ë¥˜ì˜ ë¬¸ëª… ë°œë‹¬ì— ì¤‘ìš”í•œ ì—­í• ì„ í•˜ì˜€ê³ , ì´ ì‹œëŒ€ì˜ ì—°êµ¬ëŠ” ì¸ê°„ì˜ ì—­ì‚¬ì™€ ë¬¸ëª…ì— ëŒ€í•œ ì´í•´ë¥¼ ë•ëŠ” ë° ë§¤ìš° ì¤‘ìš”í•˜ë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤\n",
      "\n",
      "------------ ì‘ë‹µì‹œê°„ : 23.99320 sec ------------\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "text = activate_agent(question=\"ì‹ ì„ê¸° ì‹œëŒ€ì˜ íŠ¹ì§•ì„ ì•Œë ¤ì¤˜\")[\"answer\"]\n",
    "end = time.time()\n",
    "\n",
    "lines = text.split(\".\")\n",
    "print()\n",
    "print(\"------------ Answer ------------\")\n",
    "for line in lines:\n",
    "    print(line)\n",
    "    \n",
    "print(f\"------------ ì‘ë‹µì‹œê°„ : {end - start:.5f} sec ------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed3406cf-b9b0-4778-b863-42fbb01a2398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ ì§ˆì˜ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. ------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "491fb9588342439dbddaef0794d40be1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ ì˜ì–´ ë‹µë³€ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤. ------------\n",
      "\n",
      "------------ ì˜ì–´ ì—ì´ì „íŠ¸ ì‹¤í–‰ ------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a49ef965934721b569cf959a08dd56",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ Answer ------------\n",
      "ì½”ë¼ë¦¬ëŠ” \"Elephant\"ì´ë¼ê³  í•©ë‹ˆë‹¤.\n",
      "\n",
      "----------- ì‘ë‹µì‹œê°„ : 7.43131 sec ------------\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "result = activate_agent(question=english)[\"answer\"]\n",
    "end = time.time()\n",
    "print(\"------------ Answer ------------\")\n",
    "print(result)\n",
    "print()\n",
    "print(f\"----------- ì‘ë‹µì‹œê°„ : {end - start:.5f} sec ------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b22d2a23-f5f3-47a6-9fc0-54d19c1a7a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ ì§ˆì˜ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤. ------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc958543da0247358eb3878bcfe9092c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------ ìˆ˜í•™ ë‹µë³€ìœ¼ë¡œ ì´ë™í•©ë‹ˆë‹¤. ------------\n",
      "\n",
      "------------ ìˆ˜í•™ ì—ì´ì „íŠ¸ ì‹¤í–‰ ------------\n",
      "\n",
      "==((====))==  Unsloth 2025.3.19: Fast Llama patching. Transformers: 4.51.1. vLLM: 0.8.3.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4070 Ti SUPER. Num GPUs = 2. Max memory: 15.688 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 8.9. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.29.post2. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10528e6651084d88b962d69a2ad519dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Will load ./math_assistant as a legacy tokenizer.\n",
      "Not an error, but Unsloth cannot patch Attention layers with our manual autograd engine since either LoRA adapters\n",
      "are not enabled or a bias term (like in Qwen) is used.\n",
      "Not an error, but Unsloth cannot patch O projection layer with our manual autograd engine since either LoRA adapters\n",
      "are not enabled or a bias term (like in Qwen) is used.\n",
      "Unsloth 2025.3.19 patched 40 layers with 0 QKV layers, 0 O layers and 40 MLP layers.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "------------ Answer ------------\n",
      " ì¢‹ì•„ìš”! ì´ ë¬¸ì œë¥¼ í•œ ë‹¨ê³„ì”© í’€ì–´ë³´ê² ìŠµë‹ˆë‹¤\n",
      "1\n",
      " **ì§ì‚¬ê°í˜•ì˜ ë‘˜ë ˆ ê³µì‹**:     ì§ì‚¬ê°í˜•ì˜ ë‘˜ë ˆëŠ” ë‹¤ìŒê³¼ ê°™ì´ ê³„ì‚°í•  ìˆ˜ ìˆì–´ìš”\n",
      "     ë‘˜ë ˆ = 2 Ã— (ê°€ë¡œ + ì„¸ë¡œ)2\n",
      " **ë¬¸ì œ ì¡°ê±´ì— ë§ì¶°ì„œ ì‹ì„ ë§Œë“¤ì–´ë³´ê¸°**:     ë¬¸ì œì—ì„œ ê°€ë¡œì˜ ê¸¸ì´ê°€ ì„¸ë¡œì˜ ê¸¸ì´ë³´ë‹¤ 9 cm ë” ê¸¸ë‹¤ê³  í•´ìš”\n",
      "     ê·¸ë˜ì„œ ê°€ë¡œë¥¼ â–¡ë¼ê³  í•˜ë©´, ì„¸ë¡œëŠ” â–¡ - 9 cmê°€ ë©ë‹ˆë‹¤\n",
      "3\n",
      " **ë‘˜ë ˆë¥¼ ì´ìš©í•œ ì‹ ë§Œë“¤ê¸°**:     ë‘˜ë ˆê°€ 50 cmë¼ê³  ì£¼ì–´ì¡Œì–´ìš”\n",
      "     ê·¸ë˜ì„œ,     2 Ã— (ê°€ë¡œ + ì„¸ë¡œ) = 50     2 Ã— (â–¡ + (â–¡ - 9)) = 504\n",
      " **ì‹ì„ ë‹¨ìˆœí™”í•˜ê¸°**:     2 Ã— (â–¡ + â–¡ - 9) = 50     2 Ã— (2â–¡ - 9) = 50     4â–¡ - 18 = 505\n",
      " **â–¡ë¥¼ êµ¬í•˜ê¸°**:     4â–¡ - 18 = 50     4â–¡ = 50 + 18     4â–¡ = 68     â–¡ = 68 Ã· 4     â–¡ = 176\n",
      " **ì„¸ë¡œ ê¸¸ì´ êµ¬í•˜ê¸°**:     ì„¸ë¡œëŠ” â–¡ - 9ì´ë‹ˆê¹Œ,     ì„¸ë¡œ = 17 - 9     ì„¸ë¡œ = 87\n",
      " **ë„“ì´ êµ¬í•˜ê¸°**:     ë„“ì´ëŠ” ê°€ë¡œ Ã— ì„¸ë¡œë¡œ êµ¬í•  ìˆ˜ ìˆì–´ìš”\n",
      "     ë„“ì´ = â–¡ Ã— (â–¡ - 9)     ë„“ì´ = 17 Ã— 8     ë„“ì´ = 136 cmÂ²ê·¸ë˜ì„œ, ì§ì‚¬ê°í˜•ì˜ ë„“ì´ëŠ” 136 cmÂ²ê°€ ë˜ê² ë„¤ìš”!**ìœ ì‚¬í•œ ë¬¸ì œë¡œ ì—°ìŠµí•´ë³´ê¸°**:  ê°€ë¡œì˜ ê¸¸ì´ê°€ ì„¸ë¡œì˜ ê¸¸ì´ë³´ë‹¤ 5 cm ë” ê¸´ ì§ì‚¬ê°í˜•ì˜ ë‘˜ë ˆê°€ 60 cmì¼ ë•Œ, ì§ì‚¬ê°í˜•ì˜ ë„“ì´ë¥¼ êµ¬í•´ë³´ì„¸ìš”\n",
      "  ê°€ë¡œë¥¼ â–¡, ì„¸ë¡œë¥¼ â–³ë¼ê³  í•˜ë©´, ê°€ë¡œëŠ” â–³ + 5ê°€ ë©ë‹ˆë‹¤\n",
      "  ë‘˜ë ˆëŠ” 2 Ã— (ê°€ë¡œ + ì„¸ë¡œ) = 60ì´ë‹ˆê¹Œ,  2 Ã— (â–³ + 5 + â–³) = 60  2 Ã— (2â–³ + 5) = 60  4â–³ + 10 = 60  4â–³ = 50  â–³ = 12\n",
      "5  ê°€ë¡œ = â–³ + 5 = 17\n",
      "5  ë„“ì´ = ê°€ë¡œ Ã— ì„¸ë¡œ = 17\n",
      "5 Ã— 12\n",
      "5 = 218\n",
      "75 cmÂ²ì´ë ‡ê²Œ ë¬¸ì œë¥¼ í’€ì–´ë³´ë©´ì„œ ì—°ìŠµí•´ë³´ì„¸ìš”!\n",
      "----------- ì‘ë‹µì‹œê°„ : 39.25943 sec ------------\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "text = activate_agent(question=math)[\"answer\"]\n",
    "end = time.time()\n",
    "lines = text.split(\".\")\n",
    "print()\n",
    "print(\"------------ Answer ------------\")\n",
    "for line in lines:\n",
    "    print(line)\n",
    "\n",
    "print(f\"----------- ì‘ë‹µì‹œê°„ : {end - start:.5f} sec ------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:langgraph]",
   "language": "python",
   "name": "conda-env-langgraph-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
